# Sharing the AI resources

I have an idea, that there should be a format of AI, which:
- Can be connected to user web pages, static or dynamic.
- Each web page contains sets of problems for AI
  - Given a Model and DataSet, fine-tune this model or do certain amount of fine-tuning.
  - Given the page has associated Prolog connections, given certain information and an instruction, follow a task.

Other users can create pages with solutions, link back and systematically ping you with their address to notify they are contributing.

Since rather each person, who can fine-tune some AI, wants to make it smarter:
- The format would allow to create study environments for an AI.

# The system: local and for web

For web, one would expect:
- Creating AI tasks as web pages.
- A task contains text, attachments, instruction (possibly in Prolog); we would use Prolog to logically connect the pieces.
- It's open for different systems to create pages with different solutions and ping the original site to make it aware of contributions.
- It would be able to define a task in different precision levels, and over time, systems can solve them in higher precision.

Imagine this:
- Instead of having lofty conversation with an AI about your software project, you create a page or forum item, assign tasks, and AI would fulfill the tasks, give you solutions and Git updates, being able to combine them.
- The same task can be watched for years, and AI generated part can be edited, fixed, changes, and thus different relations like "better version" would appear from users and AIs.
- Registering their page in different systems would open pages with solutions at these systems, able to do some tasks or to do tasks with some AI model, given some amount of resources.

The best idea would be:
- Creating a task format for an AI, which is the same, being in memory, stored on disk, or in internet. As it's made in memory, when it's interesting, it's linked to disk or web page: the script would not stop, but always carry the context, and where you would add backlink to where you want to put it (which creates a virtual link there), it would be instantly also on hard drive.
- Karmically aware system would run tries, tries to precalculate time and resources for some task at given method and precision, such as AI model; it would give karmic points for solutions, for how solution of one task helps other tasks; it would try to execute more precision levels etc. For example an object, which is constantly monitored by an user would have very good karma.
- The object contains data and attributes and each can be given solutions, and they can make their solutions better.
- Containers would have solutions for all content.

Then, you can reliably create your tasks, and while you can feed them to some AI model, the system would improve the content, try to create more connections to watch etc: consistently improve.

Tensors would be involved:
- A tensor for each task, so that the object would be _tense_ to do that task.
- Criteria for inertia: for example, user does not want to see one text constantly changing, thus it has inertia.

Active files, also aware of focus on them and object, which depend, would constantly resolve their logical problems, paradoxes, better values, and work together in one computer and between many computers; models like offline hosting, online hosting, and hosting in specialized system would be all used.

Compare this to file sharing systems like Kazaa: they had/have the karmic system by which the users evaluate each others.

While some parts of AI calculations you would rather do yourself, for many parts the process can be shared: for example, a collective of users, rather than teaching their AI only their own documents, would make the documents public and connect to different training tasks and rights. Their computers, each, would train one model with some amount of data, until it's able to generate question-answer pairs. The models would be teached, now, on these Q&A pairs or example situations. The computers involved would learn to share tasks, and for this system we would need to work hard to understand, how we can divide the systems.

# What we get

We get these abilities:
- Ability to solve our complex problems together, accumulating the data sets and generating new data.
- Ability to create loosely distributed system of logical structures: in language design I design, the same program would be able to do it's work by AI, by logic, or by users creating some solutions manually.
- Ability to work carefully: instead of asking a question from an AI, we would not get a good implementation instantly. We ask an AI for code in forum-like environment, describing the task; we can regenerate and we can create feedback, fixes, clarifications. We can create new versions of the task.
- Ability to split the task into smaller parts: where we have structured page of tasks, referring to documents, for building a system for example, we can work on each part, and work on the whole, and set some relations and important checks (such as task 5 must also check task 7 and task 7 must check summary of task 5 or some part within).

= Conclusion

_AI-generated conclusion_

The proposed framework for collaborative AI task-solving introduces a groundbreaking approach to leveraging collective resources, logical structures, and shared innovation. By enabling users to create tasks with Prolog connections, share solutions, and refine outcomes through active participation, this system enhances the efficiency and adaptability of AI models. The integration of karmic points fosters a dynamic environment where contributions are recognized and incentivized, creating a community-driven effort to continuously improve AI systems.

This visionary concept merges flexibility, precision, and innovation, offering a decentralized and scalable platform for AI development. Whether through local or web-based implementation, the system's ability to handle tasks with varying levels of precision, maintain logical coherence, and foster collaboration ensures its potential to revolutionize problem-solving and AI training. With the seamless combination of user input, AI computation, and shared datasets, this framework could redefine how artificial intelligence is utilized and refined for years to come. The pursuit of such systems not only advances technology but also creates opportunities for global collaboration and shared intelligence.