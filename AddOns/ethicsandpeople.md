# Ethics of Generative AI

I do not talk about ethics of it's content, but ethics of it's fullfilled nature: to help us.

We can see that in coming of generative AI, as in start of industrial era and appearance of machine - there were movements to destroy the factory machine:
- It will do a lot of work for us, and we need to be more creative and inspired.

Computer is now learning patterns we make habitual, and our repetitive work.

We need to:
- Become more creative.
- Spend more time on self-development and development of our crafts.
- Become less in-box.

While we were suggested all this already: existence of a learning machine does make this critical.

In capitalism and in human nature: if computer starts to take our work, it does not merely mean we would get our salaries for free. The process, rather, targets a society, which is still critical to exist: for existence, we often need to prove we are required, even to our enemies; they might be another culture we undertand none, but they still produce - everybody, want we or not, is pondering about their bread and possibility to cooperation. Peaceful coexistence - in my case, it often fails.

# Ethics of People

Instead of resisting this progress, which has not produced any results in most of the history - we walk up non-stop:
- We need to consider, how the people need to evolve, what we need to train and to think.
- It's kind of "enlightenment" to become AI-compatible people and humankind; we need to rething about what we produce and get.

# Ecosystem

Computers produce toxic effects and problems.
- We need to think, how an AI is serving the nature, and what it brings back. We need to colonize Mars and Saturn, and revitalize the ecosystem of Earth.
- Mathematics itself takes energy, but it's not necessarily this or that technology: modest computer systems can be built, which are not dangerous to the Nature, or even fit it's cycle. As well, modest performance of an AI has another effect of toxicals: if we use only some amount, they are not so dangerous, but provide benefits while falling in normal scope of effects of Natural things such as Vulcanoes.

Indeed, we need to also develop humans and life: with more effort of purposeful humans, we need less technology.

It seems kind of contra-natural to me if *everybody is having robots*: while this is almost inevitable, we need to get closer to ecorobots (with possibly ecocomputers and ecosoftware inside); 24/7 active robot might be more dangerous than cars - it's like having two cars and driving one for 10 hours a day. Having minimalistic robots and taking care of natural technological process: for us Spiritualists, rather than fighting the machine, it would be better to produce one.

# Peaceful coexistence

While computers are good in thinking, they follow our patterns.

Danger: we get an AI to do one thing, but just as we have closed all human factories and the professionals are already dead - suddenly when it's going straight within these patterns, human would be needed to get it on the right track in the changed world. This directedness equals death even in humans, so we would say that AI is "dead": it needs a reincarnation into different genesis of it's purpose and different creativity of it's will and response.

Now here is the result:
- Computers do continue our habitual tracks, especially in dangerous areas.
- Critically: a good amount of humans continues the work, but raises the quality ultimatively. While some are doing a normal work, others are relaxing, gathering inspiration, and making extra effort. In this sense, we spend more intent to each thing like cooking, cleaning or fixing cars, while less people are doing this.
- Normally: many representative jobs like waitress, as well as human observers of an AI, trainers or coaches or educators - we want to see human senses answering to us, and a luxury shop would have human workers spending time on us.
- Expecably: we have less human business, but the quality and effort or focus is much higher, because we *make it special for us*. Many routine processes have humans and AI compete in equal salary and equal natural stress or benefit.
- Ethically: we still produce work and leisure time for all the humans, and we find out the roles, which are still necessary. This is the hardest to work out: while it's ethical, it's hard to convince each manager in such things; classically, a city of America just felt so easily when it was cheaper to produce cars in India.

# Competition

Computers:
- Do have creativity and especially the one, which appears out from existing patterns of creativity; it does have intelligence, especially if it means continuation of patterns of existing intelligence.
- They do not have intuition: each kind of intuition is hard to achieve; while humans have "general intuition".

What is human intuition?
- Probably we are a very physical body and our senses are naturally connected to our physical existence: computers live in simulation, when we humans often directly follow the pressures of our physical and chemical compounds; we are like having the Elements as our ancestors.
- We are able to do this: we understand, whether a thing is pleasure to pain. We understand it about humans, to a degree about animals, plants, ecosystem and even reality in general. It's very probable that we understand the tensions and releases in materials - humans do get concerned if physical and chemical compounds get unstable or fall into excess of tension; we see beauty and uglyness in Nature, and this Nature has both biological and material structure, which rather survives and remains in it's cycles, not becoming unstable.

This natural intuition of humans is very hard to reproduce: as life, we encounter new situations and give them ethical and logical estimations without much basis; for example, seeing others becoming sick, our natural intuition is to cure them. We understand, whether the food is good or bad, whether the sunrise is beautiful, and whether something is straight nonsense. Computers do not understand all this, but learn it from our patterns.

This means: humans will not get into vegetable modes nor can they survive that way; while they spend less to routines, they put more effort into creative living.

# Foreword

Well you can go on with what computers can say and what not.

Notice that I support argumentation - rather than being completely "safe", where we are unable to see dangers and unable for real argument, such as directly using the mathematical fallacies of racism rather than thinking it's "abstract ethics", kind of contra-argument. We should be able to argue on constitutional laws rather than taking it's implications in blind faith - it's like believing in God. Science should not be based solely on authorities - this extravert position is superstition.

Also, we are based on logic and intuition as well, sharp and clear forces, not only on experimental, on the root chakra.

While the speakers are responsible: they lose a lot, if the listeners are not.
