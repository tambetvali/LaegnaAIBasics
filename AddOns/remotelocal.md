# Remote or local?

This is about generalizing the resource use of an AI.

## Cost

From the early ages, if one has an idea of programming, one can implement this even with modest hardware and software or (model) on paper. Having a piece of code, we generally do know what to do with it.

In era of Artificial Intelligence:
- Preparation: At the moment of writing, automation for turning each type of information, process flows and even discussions into learnable content for an AI lacks definite software; especially in the free software world, solutions offered are far from being robust, working solutions with one-click scripts (we cannot add one button to each file and folder in our explorer, to just add it to the learning list).
- Execution: Fine-tuning takes resources, which grows exponentially in regards to your model size - for successful learning, there are more hidden exponents, such as shuffling the data in first place to reach there. At the moment of writing, CoLab and other providers have not managed to allow me for free, accessible fine-tuning of anything more than a bot talking nonsense.
- Implementation / deployment: We would like to deploy our bot to the public, just like ChatGPT and Copilot are running all the time for everybody, but the free tiers and free bots do assign trials, monthly and daily limits, even if you only want a model with modest intelligence.

## Magic of Limits

In the software world and many other areas, there is certain magic associated with limiting yourself: one dumb, stupid limit you set to your whole system will make you plan and react in more sustainable way; while this also relates to general resource use you are part of, we are discussing your monetary limit of AI hardware.

When you buy food and coffee freely, or rent something, it's hard to keep an eye on your wallet - the extreme case, if you use a service and it automatically charges your credit card based on the usage. In this way, we get surprises and we get motives to exceed or push our limits and misunderstandings about any factor, which could do this. Especially, we rent and buy software, which has easy ways of overcoming it's limits and could respond in such way to every possibility we actually give; it could provide us things like 5-step wizards popping up automatically and being not very verbose where they push our limits, such as buying a "pro" version. When we pay based on usage time and amount of processors or memory, we also build an ecosystem, which is not very reliable with strict limits.

In programming, it seems that we have strict needs - we need professional software to meet our requirements. If the output ratio (income) given input (work, money, resource use) is growing exponentially, perhaps we are a successful corporation, our estimation to resource use might meet the solution of other provider, for example our base package is 1000€, but they would give warnings or make a phonecall if it seems we would need to pay 20 000€ this month - their experience might be to keep such clients carefully and have personal conversations, and modifications such as alarms and protection layers of their own responsibility; when this fails a bit, such as 2000€ surprise bill anyway, a corporation could spend years to analyze this "bottleneck", or search for the "bug", as they could also crash one of their many cars, decide for working day when plane fight is already arranged and paid, and do many things with 0.1% of their budget, which we normally won't consider. The fast circulation of money also involves them into something, which more looks like a "friendly family", where they are actually talking about their money with their providers, clients, other partners and aquintances.

If we try to set up a cheap service, we are considered on statistical basis and to have such voice, we need to share our problems with many people, write and sell our idea; we could often use cheap or free versions of products, whose providers try to understand, whether they can sell their more professional services without intentful "amateur" or "research" purposes - finally we just find out it was meant for schools.

In reality, a programmer has a practical purpose, and with less resources we can simplify many things we do:
- There is the absolute point, where our software starts to bring income, and with _work_ we can make it quite cheap.
- As we advance, we are spending more and more time to get less and less additional benefit, or we would turn it into a rocket science we would not afford.

For example, traffic planning is a complex task if we plan each long-distance car of our company; to simply get to each place with the cares, we need small set of rules and expectations - with even simple software, we optimize this a lot; the heavy resource need comes from the last steps in optimization: we need more computers, we need to cooperate and join with other companies to have more cars, and the programmers would become expensive, trying to push the boundaries of the market - this brings substantial income to a heavy-load corporation, which might still drop it because of complexity, price and not much understanding about whether the income would be real. The biggest income would be from removing initial bottlenecks, such as fixing a few routes of near-random configuration, manually and with quite simple programs on modest hardware - as the limits might need a very general, "holistic" plan accounting for different areas, even the education of the drivers, and which might fail because of only some unoptimized areas - we could get additional problems such as estimating weather, traffic conditions or the health of drivers, or finding clients who do not care at all to get their materials on the same day (and turn to cheaper provider, without bells and whistles).

The same way: if we have dynamic package of internet on our mobile, where we pay for a megabyte, we could just become addicted to music; the magic around such resource loss could be most generally assigned to _addiction_, where lack of heavy constraints might have multiplicity of psychological effects and local considerations about gains (and not losses). If we just have stable speed like x mb / h, a number of megabytes per hour - we learn to estimate the download speed, carefully choose the files, and we get experienced to avoid operations, which could time out; generally, we build a stable and efficient strategy. We might stop downloading 100MB planet and sky images from NASA, and download 100kb small versions, and it could turn out that for our pleasure of senses and grasp of the surroundings, the small folder of planetary miracles would be kind of better than heavy work on something we would not even completely zoom into - you got high chance that you won't scroll through _all_ of the 1GB whole-sky picture, but you would watch three most famous stars and eventually delete the image when your hard drive is getting full. The small images, in case they lack copyright - perhaps you would create your own folder with some crop and resize effects and let others download your interesting collection from a cheap and simple website.

Similarly, of our interest, as we buy a local computer (to fine-tune and deploy AI models) to work on:
- We could limit the model size, such as GPT-2 is already intelligent and even smaller models could understand some basic rules. Specialized models could run on Machine Learning instead of Deep Learning, and we could manually buy some cloud time to compute single sets of data, such as simplifying our 200 page books into 20 page outlines, then giving the outlines to our smaller local model.
- We can run AI on this computer and related interfaces and programs on other computers of our own cloud.
- We could upgrade this computer or add more similar computers to start using cloud technology, forming a "cloud".

# Absolute vs. relative measurement

Relatively, we could seek for latest development of an AI and think we got the most out of it, currently it means GPT-3 and GPT-4 for chat-based solutions or related technology. We can see this as best general solution.

Specifically, we are interested in absolute parameters:
- GPT-2 is already _intelligent_: it can discuss and be contextually aware with relatively complex data, and with some automation, we could process a book with a number of queries and optimizations, for example. GPT-3 is already talking about science very well, GPT-4 could be a genius of some matters; indeed, if we won't _hire_ a genius - then why to _deploy_ one?
  - This is not so important, how many GPT-2 instances your run on GPT-2-compliant computer: while the model size has exponential relation to resource use, specific hardware won't let you run substantially bigger models; on the other hand, making more queries to a model is linearly growing relation between hardware and software, and only advanced processing would come close to exponential processing, such as relating each query to each query - in case you have well-defined queries, each for a specific purpose, you would have a cue.
- Your computer, thus, would enable certain levels of an AI.
- Absolutely, a company of given size, possibility and effort does need specific complexity of calculations, processing and intelligence: consider the operations you do on paper and your mind, if you are asked for additional qualities - you get tired easily, for example trying each combination of how to route your 3 cars through 20 positions; while it's near-solvable if you have time, you can try many combinations, most people would rather draw some intuitive, less efficient lines and stare at them for some time to notice obvious improvements; they would get angry, tired and quite negative towards you if you introduce methods for efficient combinations. Similarly, an intelligent, or wise rather than intelligent if the latter is quantitative, computer would also get bored and tired, given such excess of measures. You might not notice this bottleneck with advanced software, and it might rent additional time for many tasks - on a simple computer, you would analyze your *absolute* needs, where your business might run smoothly as you work on possible optimizations and developments *slowly*, and implement them as they *reach simplicity*, not as they *reach the market*.

For example, one could cook food for 3 days in advance, especially if it's eaten cold and meant to be kept in a freezer - well, more often than not, 3 days of tasty food would be eaten in first hour and for _addiction_, one would hardly avoid the pleasure that close - the negative effect might not be buying less food, but for example travelling less. I had a period, when my freezer tended to be full of food; surprisingly, I did eat less and throw it away. The other possibility is that you buy *everything* in advance for a week: you would need to control yourself, to explain your guests about some limits like icecream a day, etc. While it's common to buy base products of food such way, it's less common to buy junk food like this, or addictive food - it's not easy to prove that your software producers are not interested to provoke addiction, or that they would be unsuccessful; for example, costly button "Think Deeper" could suddenly appear and it would take experience to decide, who and when and why could use this - should you put this button into your own model, it would sometimes make you wait longer, but the strategies and optimizations to get more uptime and avoid lags would guide you to proper development.
