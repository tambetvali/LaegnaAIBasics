# Laegna binary-distribution encoding

```markdown
IOAE
```

Those encode two bits:

$Higher \in significance$ `bit 0` is `value 0`bit: either I or A.

$Higher \in significance$ `bit 0` is `value 1` bit: either O or E.

$Lower \in significance$ `bit 1` is `value 0`bit: either I or A.

$Lower \in significance$ `bit 1` is `value 1` bit: either O or E.

Notice if list dimension has first index set to 1, instead of zeroeth index set to 0: to convert between *older* (set theory) and *newer* (automation and indexing), you just add or remove 1, for all of the list indexes.

You use higher significance for exponent, and lower significance for normal growth; you might try to remap range of this exponent to the mantissa part of float, to it's much smaller angle.

Then you add second dimension:

These can be mapped to *plus and minus* vs *division and multiplication* in various ways:

* In various ways, you need two-frequential space: range and instance $\in instance$ - ***in instance*** converts to domain and range $\in class$ - ***in class***.

I use two dimensional system:

```markdown
KJIL
QPOR
CBAD
GFEH
```

This provides several mnemonics, including that *vocal = 1* and $XOR$ dimension is $True$ for the axe unit - this can remove linearities, as in Deep Learning itself: layer's input is mapped to alphabetic direction of each row, unchanged for columns, and still the numeric order of this. Numbers -2, -1, 1 and 2 can be used.

---

```markdown
ILKJ
ORQP
ADCB
EHGF
```

This generalizes last two significance bits in each row, without changing the pointer in row number; previous general pointer becomes a partial instance id, which is now part of an instance. Numbers 1, 2, 3 and 4 can be used: this is the 1-based linear display.

For indexing in vectors and multidimensional systems, numbers 0, 1, 2, 3 can be used for columns and rows.

In activation function, this format can be converted to non-generalized form. I have used classic numbers 1-8 where these two, linear and already exponential are projected in row: in case the major frequency 5-8 (maps mult. and div.) contains minus, this is *worse* than if the minor frequency 1-4 (maps plus and minus) contains zero or one based positive numbers.

For zero, because systems start from -0 and +0, or -1 and +1 - a *continuous* or *discrete* form of presentation, altough it's up to you what you do with each format: inside, the zero itself is visibly divided (***probability factor $A$***).

```markdown
U
```

For symbolic infinity, abstract symbols are used(***probability factor E***).

```markdown
U - but upside down; flip or mirror so that it looks like "union"
```

In decimal representation or linearization, both `U` and `U!!upsidedownmirror` are the following number (***probability factor 1/8***, generalization -1).:

```markdown
0
```



Those have opposite projections

What is "established solely for other members", sacrifice or efficiency factor in public or network; U is unknown and will be based on other letters, while V does not care (***probability factor O***).:

```markdown
V
```

For symbolic infinity, abstract symbols are used(***probability factor I***)..

```markdown
W
```

In decimal representation or linearization, both `U` and `U!!upsidedownmirror` are the following number (***probability factor 1/4***, generalization +1).:

```markdown
0
```

Subzero numbers as units promote growth, where exponents promote long-term growth and sustainability. Linear numbers promote everyday activities and constant numbers are stable bones of activities.

Now lets go into binary, `one bit` representation.

`Bit 0` is 0 (***probability factor O***); one-dimensional `U`, and signed value of 0 is -1 till the day of death.

`Bit 0` is A (***probability factor O***); one-dimensional `V`, and signed value of 1 is +1 till the world ends, but only in this system. You are free to adapt and enchange, and this should set up some initial ideas: my mnemonics on alphabet.

```markdown
U - bit value is 0; -1; False
V - bit value is 1; +1; True
```

We use sign mappings in fractals: in number system, if stacked implications are continuous in exponent, activator function spaces: each layer or consequentive *vector* calculation maps into passatge of some form of time: implication, real-time or exponent ratio. Number digits stack, but also in each dimension: when we multiply, divide, add and substract: for first two, we need to create 4 elements in each dimension of values, to view them in multifrequential basis of band width of observation window, and topological causatge of same-unit point topology in any relation to reality, accelerated acces show their slightest changes in *outside* layers, and this passatges like time: constantly having certain acceleration factor, like constantly using fuel, space wing or solar panel to move faster and faster: moves us to exponentially growing space, which might accelerate over boundaries of numeric space.

This number system is freely remappable and invented to provide various ideas and connect various fields.

```markdown
UU + +2 + 4 U, but upside down
UV + +1 + 3 W, index 3
VU - -1 + 2 V, index 0,5
VV - -2 + 1 U, index 1
```

We can map frequency shifts in octaves in various ways:

- Lets imagine differential and integral levels in continuous space

- Base higher unit maps constant to constant number, linear to linear number, exponent to exponent. This grows into absolute infinity, but does not behave well instead it's binary for both unit and value system, by which we have extended matrices and relations: such as unit-number relation provided in this axiomatic entry point.

- Base lower unit maps linearly, and projective or unit vector equals projected, object transforming or number vector.



# Remapping $OA$ (`0:1`) to $IOAE$ (`00:01:10:11`) and higher octave $OA$ (`00/01:10/11` vs IE `00/10:10/11` or $OA$ with reversed first pair)

We cover first two: read the fucking titles :)



We have temporal dimension:

- This is the outer dimension of generalizer, `significant bit`.



Based on definition, spatial follows:

* This is the inner dimension, `insignificant bit`.

* While it's index value is considered, it's more active in plus and minus operation flow, than in single multiplication or division: where, rather, only the significant bits matter.



# Number growth rules

Mapping two numbers into single dimension of operation:

* Operation has two bits in one side, and one bit in yielding result.

* They provide parents *upwards*, children *downwards*, altough it might be a binary mapping for us.



**Multiplication *and* division**:

you *Might want*

* Each bit is more significant for multiplication, and you might multiply positive numbers with 2 in common unit.

* Each bit is less significant for division, and you might divide negative numbers by 2 if they were linear, but actually *multiply* with two in other direction.

* In reverse, go back in this exponent unit as many times you want.

***Base rules***

In multiplication, if you combine two binary bits together, you use two-bit dimension; here they naturally behave as 1 and 2, but other dimensions such as -1 and +1 can be projected; notice while -1 and +1 do not change the base dimension, as you multiply and divide them: the result, with dimensions added and each digit space numbered with plus or minus.

Any multiplication: for example, if dimension had precision 2, now it has precision 4 and power 2: if unit was in R, now it's in R^2, but equivalent number in even distribution, where sizes of the whole R of real number set matters as higher contribution of exponent unit, and single number is then either on exponent or linear scale.

We call the class Domain $R$ and Range $T$, or instances, respectively, have Range $R$ and Value $T$, where they contain values and not their types or ordered distributions like the sets themselves.

Multiplication: positive dimension is added to dimensional number, bits shifted left and last bit is added, with plus dimensional reference.

Division: if one number is divided with another, depending on sign of the other the dimension is $T$ - a `Ç¹egative metabit 0` , or for minus sign it's `positive metabit 1`, $R$. $O$ and $A$ are instance, $U$ and $V$ (X => Y) or $V$ and $U$ (Z=>X dimension) are random number distributions either $U$ will conclude another random number, or the $V$ digit is gone as if it did not exist in my most metaphysical way.



Often, I use numbers `-2` and `-1`, or in one-bit number I often use `-1` in this matter, to calculate with decceleration property: with projection of 0, the deccelerative values are slowly speeding up, but each new value is deccelerative as long as the result is in future, and it gains accelerative component rather from gains; deccelerative from work, input, intent or no-intent sacrifices and donations or help. In left-wing systems, accelerative gain measures sustainable (E), or deccelerative growth measures survival or death, a local optimum or it's resolution (A); while zero is substance, frozen like ice; linear growth is (A) and linear counter-growth is (O); O might make first number linearly smaller, where second number linearly grows, and divides higher frequency into two octaves on lower, binary digit we need for collapse in new dimensions we create.



Best number representation:

- Each number digit counts plus and minus respectively, and belongs to number class within range of this number of digits. Different ranges project to same spaces, with digits growing to smaller and higher dimension at same time.



**Addition *and* subtraction**

Here, we need dimension *inwards in fractal*

Addition, such as adding two numbers: they are two digits and two digits.

- Result is in three digit space: we add as many information bits as with multiplication and division, as we keep references to all bits in logic, and design a workflow: new square of precision appears, but at maximum, the same unitary dimension is used for one full digit, and by chance, many numbers can be added or substracted before dimensions start to grow - in exponent number of operations, the number itself becomes into calculation effort and optimization, and plus or minus when repeated, turn into operations in higher scopes, such as division and multiplication in first symmetric order, the "second sphere" in old language.

- Minus, for negative numbers, projects this space into respectively sign-altered alternatives of information digits which appear when first and second operand is plus operand; you find this by bounding a box: how negative numbers you can reach, how positive, and what is the relational density.



When multiplication and division change the space dimension:

- They convert units like $R$ for real number set, or $cm$ for length, into square units like $R^2$ to denote it has square power, or *cm^2* to denote it's actually a supereme $squaremeter$, not a $lineometer$.

- This remaps common exponent set:
  
  - We still follow more and less significant bits, and mostly rearrange the bits in this space.
  
  - Each digit, linearly, has space of zeroes and one 1, where value-space matrix is applied; if same number system refers to number positions, which are there linearly: two digits might even equal minus one digits, unit mapping converts to this.



# Combining operations

Calculate lower bounds with each dimension, sign (lin. anchor), correlation with -1 or 1 (exp. anchor); remember an exponent behaviours are like irrational part, so use complex numbers: their internal sign does not map directly back to main sign, but rather into change of it; left side can be switched, left and right, to have 1/4 acceleration of number system digit space over XOR and paradoxes, when related to normal dimensions and calculated accordingly. One can happen with dimensions, the other with values.



Exponents:

```
OA are non-exponent axe (linear in non-signed, static or deccelerative in
signed number).

IE are exponent axe.
```

If you have two 4-based bits, you have 2 bits for both two axes: they do not accelerate into exponent resource use for single value, rather:

You map this in new dimension made by operation, and full operation boundary space and reprojection rules are used to understand units, when their powers (number unit^power map with each others); the following is multiplication table where two dimensional bit is formed from both aspects which are used in calculation, which itself keeps itself upside-up:

```markdown
AA - mapped into solution digit A, garbage digit A
     two bit value: 4
     two bit signed value: -2
     two bit natindex value: 8
AO - mapped into solution digit A, garbage digit O
     two bit value: 2
     two bit signed value: -2
     two bit natindex value: 4
OA - mapped into solution digit O, garbage digit A
     two bit unsigned value: 1
     two bit signed value: -1
     two bit natindex value: 2
OO - mapped into solution digit O, garbage digit O
     two bit unsigned value: 0
     two bit signed value: -1
     two bit natindex value: 1
```

In plus and minus, likely the less significant bits provide more interest, as they directly interact with bits in the result.

Here, we see: bits are coming or going, but things are consistent.



This does not restrict you to binary number:

- Set a shift (add, bias) and scope (multiply, weight) for the value, such as:

- Number system allows digits 0-7
  
  - Now, for getting the two-digit range in the same system, where even in binary digits maybe you use more than perfectly bound digit counts such as 1, 2 or 4, 49 is used: higher order digit is 0, if 0/49 to 6/49 part is relative to lower digit, and if higher order digit is 6, lower order 0 would conclude to 42 and lower order 7 gives 48, the last number in 0-based array.
  
  - Digits, to higher orders, are thus mapped separately, and higher order gives separate order, which relates to acceleration factor: significant bits get more significant in higher orders, while less significant bits seem less significant, unless value is repeated in magnitude of the higher order, rather than it's direct visibility.


